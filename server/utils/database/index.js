const { getGitVersion } = require("../../endpoints/utils");
const { Telemetry } = require("../../models/telemetry");

function checkColumnTemplate(tablename = null, column = null) {
  if (!tablename || !column)
    throw new Error(`Migration Error`, { tablename, column });
  return `SELECT COUNT(*) AS _exists FROM pragma_table_info('${tablename}') WHERE name='${column}'`;
}

// Note (tcarambat): Since there is no good way to track migrations in Node/SQLite we use this simple system
// Each model has a `migrations` method that will return an array like...
// { colName: 'stringColName', execCmd: `SQL Command to run when`, doif: boolean },
// colName = name of column
// execCmd = Command to run when doif matches the state of the DB
// doif = condition to match that determines if execCmd will run.
// eg: Table workspace has slug column.
// execCmd: ALTER TABLE DROP COLUMN slug;
// doif: true
// => Will drop the slug column if the workspace table has a column named 'slug' otherwise nothing happens.
// If you are adding a new table column if needs to exist in the Models `colsInit` and as a migration.
// So both new and existing DBs will get the column when code is pulled in.

async function checkForMigrations(model, db) {
  if (model.migrations().length === 0) return;
  const toMigrate = [];
  for (const { colName, execCmd, doif } of model.migrations()) {
    const { _exists } = await db.get(
      checkColumnTemplate(model.tablename, colName)
    );
    const colExists = _exists !== 0;
    if (colExists !== doif) continue;

    toMigrate.push(execCmd);
  }

  if (toMigrate.length === 0) return;

  console.log(`Running ${toMigrate.length} migrations`, toMigrate);
  await db.exec(toMigrate.join(";\n"));
  return;
}

// Note(tcarambat): When building in production via Docker the SQLite file will not exist
// and if this function tries to run on boot the file will not exist
// and the server will abort and the container will exit.
// This function will run each reload on dev but on production
// it will be stubbed until the /api/migrate endpoint is GET.
async function validateTablePragmas(force = false) {
  try {
    if (process.env.NODE_ENV !== "development" && force === false) {
      console.log(
        `\x1b[34m[MIGRATIONS STUBBED]\x1b[0m Please ping /migrate once server starts to run migrations`
      );
      return;
    }
    const { SystemSettings } = require("../../models/systemSettings");
    const { User } = require("../../models/user");
    const { Workspace } = require("../../models/workspace");
    const { WorkspaceUser } = require("../../models/workspaceUsers");
    const { Document } = require("../../models/documents");
    const { DocumentVectors } = require("../../models/vectors");
    const { WorkspaceChats } = require("../../models/workspaceChats");
    const { Invite } = require("../../models/invite");
    const { WelcomeMessages } = require("../../models/welcomeMessages");
    const { ApiKey } = require("../../models/apiKeys");

    await SystemSettings.migrateTable();
    await User.migrateTable();
    await Workspace.migrateTable();
    await WorkspaceUser.migrateTable();
    await Document.migrateTable();
    await DocumentVectors.migrateTable();
    await WorkspaceChats.migrateTable();
    await Invite.migrateTable();
    await WelcomeMessages.migrateTable();
    await ApiKey.migrateTable();
  } catch (e) {
    console.error(`validateTablePragmas: Migrations failed`, e);
  }
  return;
}

// Telemetry is anonymized and your data is never read. This can be disabled by setting
// DISABLE_TELEMETRY=true in the `.env` of however you setup. Telemetry helps us determine use
// of how AnythingLLM is used and how to improve this product!
// You can see all Telemetry events by ctrl+f `Telemetry.sendTelemetry` calls to verify this claim.
async function setupTelemetry() {
  if (process.env.DISABLE_TELEMETRY === "true") {
    console.log(
      `\x1b[31m[TELEMETRY DISABLED]\x1b[0m Telemetry is marked as disabled - no events will send. Telemetry helps Mintplex Labs Inc improve AnythingLLM.`
    );
    return true;
  }

  if (Telemetry.isDev()) {
    console.log(
      `\x1b[33m[TELEMETRY STUBBED]\x1b[0m Anonymous Telemetry stubbed in development.`
    );
    return;
  }

  console.log(
    `\x1b[32m[TELEMETRY ENABLED]\x1b[0m Anonymous Telemetry enabled. Telemetry helps Mintplex Labs Inc improve AnythingLLM.`
  );
  await Telemetry.findOrCreateId();
  await Telemetry.sendTelemetry("server_boot", {
    commit: getGitVersion(),
  });
  return;
}

// –ú–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è PostgreSQL - —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã event_logs
async function migratePostgreSQL() {
  try {
    const dbUrl = process.env.DATABASE_URL;
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ PostgreSQL
    if (!dbUrl || !dbUrl.startsWith('postgresql://')) {
      console.log('\x1b[33m[POSTGRESQL MIGRATION SKIPPED]\x1b[0m DATABASE_URL –Ω–µ —è–≤–ª—è–µ—Ç—Å—è PostgreSQL');
      return { success: true, skipped: true };
    }

    // –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    let connectionString = dbUrl;
    
    // –ï—Å–ª–∏ —ç—Ç–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∞–¥—Ä–µ—Å Railway, –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—É–±–ª–∏—á–Ω—ã–π
    if (dbUrl.includes('railway.internal')) {
      if (process.env.DATABASE_PUBLIC_URL) {
        connectionString = process.env.DATABASE_PUBLIC_URL;
        console.log('‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é DATABASE_PUBLIC_URL –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏');
      } else if (process.env.RAILWAY_TCP_PROXY_DOMAIN && process.env.RAILWAY_TCP_PROXY_PORT) {
        const user = process.env.PGUSER || process.env.POSTGRES_USER || 'postgres';
        const password = process.env.PGPASSWORD || process.env.POSTGRES_PASSWORD;
        const database = process.env.PGDATABASE || process.env.POSTGRES_DB || 'railway';
        
        if (password) {
          connectionString = `postgresql://${user}:${password}@${process.env.RAILWAY_TCP_PROXY_DOMAIN}:${process.env.RAILWAY_TCP_PROXY_PORT}/${database}`;
          console.log('‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω –ø—É–±–ª–∏—á–Ω—ã–π URL –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è');
        }
      }
    }
    // –ï—Å–ª–∏ DATABASE_URL —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É–±–ª–∏—á–Ω—ã–π –∞–¥—Ä–µ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, mainline.proxy.rlwy.net), –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    else if (dbUrl.includes('.proxy.rlwy.net') || dbUrl.includes('.railway.app')) {
      console.log('‚úÖ DATABASE_URL —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É–±–ª–∏—á–Ω—ã–π –∞–¥—Ä–µ—Å Railway, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ');
      connectionString = dbUrl;
    }

    const { Client } = require('pg');
    const fs = require('fs');
    const path = require('path');

    // –ß—Ç–µ–Ω–∏–µ SQL —Å–∫—Ä–∏–ø—Ç–∞
    const sqlPath = path.join(__dirname, '../../prisma/migrations/create_event_logs_postgresql.sql');
    let sql;
    try {
      sql = fs.readFileSync(sqlPath, 'utf8');
    } catch (error) {
      console.error(`\x1b[31m[POSTGRESQL MIGRATION ERROR]\x1b[0m –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ SQL —Ñ–∞–π–ª–∞: ${error.message}`);
      return { success: false, error: error.message };
    }

    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π SSL –¥–ª—è Railway PostgreSQL
    // Railway –∏—Å–ø–æ–ª—å–∑—É–µ—Ç postgres-ssl –æ–±—Ä–∞–∑, –∫–æ—Ç–æ—Ä—ã–π —Ç—Ä–µ–±—É–µ—Ç SSL —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    // –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ SSL –ø–æ –∞–¥—Ä–µ—Å—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    const needsSSL = connectionString.includes('.proxy.rlwy.net') || 
                     connectionString.includes('.railway.app') ||
                     process.env.RAILWAY_TCP_PROXY_DOMAIN ||
                     process.env.DATABASE_PUBLIC_URL;
    
    const clientConfig = {
      connectionString: connectionString,
      // –í–∫–ª—é—á–∞–µ–º SSL –¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ Railway (postgres-ssl –æ–±—Ä–∞–∑)
      ssl: needsSSL ? {
          rejectUnauthorized: false, // Railway –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
        } : undefined,
    };
    
    if (needsSSL) {
      console.log('üîí –ò—Å–ø–æ–ª—å–∑—É—é SSL —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è Railway PostgreSQL');
    }

    const client = new Client(clientConfig);

    try {
      console.log('\x1b[34m[POSTGRESQL MIGRATION]\x1b[0m –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...');
      await client.connect();
      console.log('‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö');

      console.log('üìù –ü—Ä–∏–º–µ–Ω—è—é –º–∏–≥—Ä–∞—Ü–∏—é event_logs...');
      await client.query(sql);
      console.log('‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞!');

      // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
      const result = await client.query(`
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name = 'event_logs'
      `);

      if (result.rows.length > 0) {
        console.log('‚úÖ –¢–∞–±–ª–∏—Ü–∞ event_logs —Å—É—â–µ—Å—Ç–≤—É–µ—Ç');
      } else {
        console.log('‚ö†Ô∏è  –¢–∞–±–ª–∏—Ü–∞ event_logs –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏');
      }

      return { success: true, skipped: false };
    } catch (error) {
      // –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
      if (error.message.includes('already exists') || error.message.includes('—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')) {
        console.log('üí° –¢–∞–±–ª–∏—Ü–∞ event_logs —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ');
        return { success: true, skipped: false, alreadyExists: true };
      } else {
        console.error(`\x1b[31m[POSTGRESQL MIGRATION ERROR]\x1b[0m ${error.message}`);
        return { success: false, error: error.message };
      }
    } finally {
      await client.end();
    }
  } catch (error) {
    console.error(`\x1b[31m[POSTGRESQL MIGRATION ERROR]\x1b[0m ${error.message}`);
    return { success: false, error: error.message };
  }
}

module.exports = {
  checkForMigrations,
  validateTablePragmas,
  setupTelemetry,
  migratePostgreSQL,
};
